import "dotenv/config"
import fs from "fs"
import path from "path"
import OpenAI from "openai"

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! })

const BATCH_SIZE = 100       // –°–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
const PARALLEL_LIMIT = 5     // –°–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

async function createEmbeddingsBatch(items: any[]) {
  const inputs = items.map(
    (p) => `${p.name || ""} ${p.brand || ""} ${p.category || ""}`.trim()
  )

  const response = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: inputs,
  })

  return response.data.map((d, i) => ({
    ...items[i],
    embedding: d.embedding,
  }))
}

async function processBatches(products: any[], existing: Record<string, any>) {
  const outPath = path.join(process.cwd(), "public", "dealer_vectors.json")
  const total = products.length
  const batches = []

  for (let i = 0; i < total; i += BATCH_SIZE) {
    batches.push(products.slice(i, i + BATCH_SIZE))
  }

  const results: any[] = []
  let completed = 0
  console.log(`üì¶ –ù–∞—á–∏–Ω–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é ${total} —Ç–æ–≤–∞—Ä–æ–≤...`)

  async function runBatch(batch: any[]) {
    try {
      const vectors = await createEmbeddingsBatch(batch)
      results.push(...vectors)
      completed += batch.length
      console.log(`‚úÖ ${completed}/${total} —Ç–æ–≤–∞—Ä–æ–≤ –≥–æ—Ç–æ–≤–æ`)
    } catch (err) {
      console.error("‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ:", err)
    }
  }

  // –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
  const queue = [...batches]
  const workers = Array.from({ length: PARALLEL_LIMIT }, async () => {
    while (queue.length > 0) {
      const batch = queue.shift()
      if (batch) await runBatch(batch)
    }
  })

  await Promise.all(workers)

  // üîÑ –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—ã–µ –∏ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
  const merged: Record<string, any> = { ...existing }
  for (const p of results) {
    merged[p.sku] = p
  }

  const outputArray = Object.values(merged)
  fs.writeFileSync(outPath, JSON.stringify(outputArray, null, 2), "utf8")

  console.log(`üöÄ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±–Ω–æ–≤–ª–µ–Ω–æ ${results.length} —Ç–æ–≤–∞—Ä–æ–≤. –í—Å–µ–≥–æ: ${outputArray.length}`)
}

async function main() {
  const dealerPath = path.join(process.cwd(), "public", "dealer.json")
  const vectorPath = path.join(process.cwd(), "public", "dealer_vectors.json")

  if (!fs.existsSync(dealerPath)) {
    console.error("‚ùå dealer.json –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    process.exit(1)
  }

  const dealerData = JSON.parse(fs.readFileSync(dealerPath, "utf8"))
  const existing: Record<string, any> = {}

  if (fs.existsSync(vectorPath)) {
    const oldData = JSON.parse(fs.readFileSync(vectorPath, "utf8"))
    for (const p of oldData) {
      if (p.sku) existing[p.sku] = p
    }
    console.log(`üìÇ –ù–∞–π–¥–µ–Ω–æ ${oldData.length} –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤`)
  }

  // ‚öôÔ∏è –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –∏–ª–∏ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
  const newProducts = dealerData.filter((p: any) => {
    const existingItem = existing[p.sku]
    // –µ—Å–ª–∏ –Ω–µ—Ç –∏–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –Ω–∞–∑–≤–∞–Ω–∏–µ, –±—Ä–µ–Ω–¥ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è
    if (!existingItem) return true
    if (
      existingItem.name !== p.name ||
      existingItem.brand !== p.brand ||
      existingItem.category !== p.category
    )
      return true
    return false
  })

  if (newProducts.length === 0) {
    console.log("‚úÖ –í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã. –ù–µ—á–µ–≥–æ –æ–±–Ω–æ–≤–ª—è—Ç—å.")
    return
  }

  console.log(`üß† –ù–æ–≤—ã—Ö –∏–ª–∏ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: ${newProducts.length}`)
  await processBatches(newProducts, existing)
}

main().catch(console.error)
