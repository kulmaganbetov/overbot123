// scripts/updateDealer.ts
import { Client } from "basic-ftp"
import "dotenv/config"
import fs from "fs"
import path from "path"
import Papa, { ParseResult } from "papaparse"
import iconv from "iconv-lite"
import { openai } from "@/lib/openai"

const FTP_CONFIG = {
  host: process.env.FTP_HOST || "over-shop.kz",
  user: process.env.FTP_USER || "zoomos1",
  password: process.env.FTP_PASSWORD || "FJsV6cFv",
  port: Number(process.env.FTP_PORT || 21),
}

const REMOTE_PATH = "/Dealer.csv"
const LOCAL_CSV_PATH = path.join(process.cwd(), "public", "Dealer.csv")
const LOCAL_JSON_PATH = path.join(process.cwd(), "public", "dealer.json")
const LOCAL_VECTORS_PATH = path.join(process.cwd(), "public", "dealer_vectors.json")

export async function updateDealerFile() {
  const client = new Client()
  client.ftp.verbose = true

  try {
    console.log("üì° –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ FTP...")
    await client.access({ ...FTP_CONFIG, secure: false })
    client.ftp.socket?.setTimeout(15000)

    console.log("‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–µ–º Dealer.csv...")
    await client.downloadTo(LOCAL_CSV_PATH, REMOTE_PATH)
    console.log("‚úÖ Dealer.csv —Å–∫–∞—á–∞–Ω:", new Date().toLocaleString())

    // —á–∏—Ç–∞–µ–º CSV
    const buffer = fs.readFileSync(LOCAL_CSV_PATH)
    const text = iconv.decode(buffer, "win1251")
    console.log("üî§ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É CP1251 (Windows-1251)")

    // –ø–∞—Ä—Å–∏–º CSV
    let parsed: ParseResult<Record<string, string>> = Papa.parse(text, {
      header: true,
      skipEmptyLines: true,
      delimiter: ";",
    })

    if (
      parsed.data.length === 0 ||
      !parsed.data[0] ||
      !("–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞" in parsed.data[0])
    ) {
      parsed = Papa.parse<Record<string, string>>(text, {
        header: true,
        skipEmptyLines: true,
        delimiter: ",",
      })
      console.log("‚öôÔ∏è –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ –∑–∞–ø—è—Ç—É—é (,) –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å")
    }

    console.log("üìä –ü—Ä–æ—á–∏—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫:", parsed.data.length)
    console.log("üßæ –ó–∞–≥–æ–ª–æ–≤–∫–∏:", Object.keys(parsed.data[0] || {}))

    const products = parsed.data
      .filter((p) => p["–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞"])
      .map((p) => ({
        sku: (p["SKU"] || "").trim(),
        kaspiCode: (p["–ö–æ–¥–ö–∞—Å–ø–∏"] || "").trim(),
        name: (p["–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞"] || "").trim(),
        supplier: (p["–ü–æ—Å—Ç–∞–≤—â–∏–∫"] || "").trim(),
        stock: Number((p["–û—Å—Ç–∞—Ç–æ–∫"] || "0").replace(/\s+/g, "")) || 0,
        price: Number((p["–¶–µ–Ω–∞"] || "0").replace(/\s+/g, "")) || 0,
        retail: Number((p["–†–†–¶"] || "0").replace(/\s+/g, "")) || 0,
        article: (p["–ê—Ä—Ç–∏–∫—É–ª"] || "").trim(),
        brand: (p["–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å"] || "").trim(),
        credit: (p["–ö—Ä–µ–¥–∏—Ç–†–∞—Å—Å—Ä–æ—á–∫–∞"] || "").trim(),
        bonus: (p["–ë–æ–Ω—É—Å–Ω–∞—è–¶–µ–Ω–∞"] || "").trim(),
        special: (p["–°–ø–µ—Ü–¶–µ–Ω–∞"] || "").trim(),
        warranty: (p["–°—Ä–æ–∫–ì–∞—Ä–∞–Ω—Ç–∏–∏"] || "").trim(),
        category: (p["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] || "").trim(),
        supplierCode: (p["–ö–æ–¥–ü–æ—Å—Ç–∞–≤—â–∏–∫–∞"] || "").trim(),
      }))

    fs.writeFileSync(LOCAL_JSON_PATH, JSON.stringify(products, null, 2), "utf8")
    console.log(`üíæ –û–±–Ω–æ–≤–ª–µ–Ω–æ ${products.length} —Ç–æ–≤–∞—Ä–æ–≤ –≤ dealer.json`)

    // üß† –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    await createVectorIndex(products)
  } catch (err) {
    console.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Dealer.csv:", err)
  } finally {
    client.close()
  }
}

async function createVectorIndex(products: any[]) {
  console.log("üß† –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–±–∞—Ç—á–∞–º–∏) + keywords...")
  const LOCAL_VECTORS_PATH = path.join(process.cwd(), "public", "dealer_vectors.json")
  const batchSize = 400
  const total = Math.min(products.length, 10000)
  const allVectors: { sku: string; vector: number[]; keywords?: string }[] = []

  for (let i = 0; i < total; i += batchSize) {
    const batch = products.slice(i, i + batchSize)
    const texts = batch.map((p) => {
      // keywords: –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ–ª—è –¥–ª—è –ª—É—á—à–µ–≥–æ match
      const kw = [p.name, p.brand, p.category, p.article, p.sku, p.kaspiCode].filter(Boolean).join(" ")
      return `${kw}`
    })

    console.log(`‚û°Ô∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ${i + 1}‚Äì${i + batch.length} / ${total}`)
    const embeddings = await openai.embeddings.create({ model: "text-embedding-3-small", input: texts })
    const vectors = embeddings.data.map((e: any, idx: number) => ({
      sku: batch[idx].sku,
      vector: e.embedding,
      keywords: texts[idx],
    }))
    allVectors.push(...vectors)
  }

  fs.writeFileSync(LOCAL_VECTORS_PATH, JSON.stringify(allVectors, null, 2), "utf8")
  console.log(`‚úÖ –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω (${allVectors.length} –∑–∞–ø–∏—Å–µ–π)`)
}



if (require.main === module) {
  updateDealerFile().catch((err) => {
    console.error(err)
    process.exit(1)
  })
}
